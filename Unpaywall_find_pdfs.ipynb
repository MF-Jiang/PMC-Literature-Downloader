{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function: download_from_unpaywall\n",
    "\n",
    "Description:\n",
    "    This script simulates retrieving article PDFs using the Unpaywall service.\n",
    "    For each DOI extracted from the input CSV file, the script constructs the Unpaywall API URL\n",
    "    and attempts to download the corresponding full-text PDF.\n",
    "\n",
    "Inputs:\n",
    "    csv_path : str\n",
    "        Path to the input CSV file (e.g., \"literature list - pubmed.csv\") containing a 'DOI' column.\n",
    "    out_dir : str\n",
    "        Directory where downloaded PDF files will be saved (e.g., \"papers\").\n",
    "    email : str\n",
    "        Contact email address (must end with \".edu\") required by the Unpaywall API for access.\n",
    "\n",
    "Process:\n",
    "    - Extract DOI values from the CSV file.\n",
    "    - Build Unpaywall URLs using the DOI and email.\n",
    "    - Attempt to download each articleâ€™s PDF and save it to the output directory.\n",
    "\n",
    "Notes:\n",
    "    - Some PDFs may be downloaded incorrectly or be unreadable.\n",
    "    - Check and remove any leftover \".part\" files or invalid PDF files.\n",
    "\"\"\"\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm"
   ],
   "id": "5daeec5d3104e124"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize_col(col: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", col.strip().lower())\n",
    "\n",
    "\n",
    "def find_col(cols, candidates):\n",
    "    norm = {normalize_col(c): c for c in cols}\n",
    "    for cand in candidates:\n",
    "        key = normalize_col(cand)\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "def safe_filename(name: str, maxlen: int = 150) -> str:\n",
    "    name = re.sub(r\"[\\\\/:*?\\\"<>|]+\", \"_\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return (name[:maxlen].rstrip() or \"paper\") + \".pdf\"\n",
    "\n"
   ],
   "id": "779cdb5ada3082cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_pdf_url_from_unpaywall(doi: str, email: str, session: requests.Session):\n",
    "\n",
    "    url = f\"https://api.unpaywall.org/v2/{doi}?email={email}\"\n",
    "    r = session.get(url, timeout=30)\n",
    "    if r.status_code != 200:\n",
    "        return None, f\"unpaywall_status_{r.status_code}\"\n",
    "\n",
    "    data = r.json()\n",
    "    loc = data.get(\"best_oa_location\") or {}\n",
    "    pdf = loc.get(\"url_for_pdf\")\n",
    "    if pdf:\n",
    "        return pdf, \"\"\n",
    "\n",
    "    for loc in data.get(\"oa_locations\") or []:\n",
    "        if loc.get(\"url_for_pdf\"):\n",
    "            return loc[\"url_for_pdf\"], \"\"\n",
    "    return None, \"no_oa_pdf\""
   ],
   "id": "d5de78f3053c3cb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def stream_download(url: str, out_path: Path, session: requests.Session,\n",
    "                    chunk=1024 * 256, timeout=60):\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with session.get(url, stream=True, timeout=timeout, allow_redirects=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total = int(r.headers.get(\"Content-Length\", \"0\")) or None\n",
    "        with open(out_path, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=out_path.name) as pbar:\n",
    "            for chunk_data in r.iter_content(chunk_size=chunk):\n",
    "                if chunk_data:\n",
    "                    f.write(chunk_data)\n",
    "                    pbar.update(len(chunk_data))"
   ],
   "id": "56b23dac39a6b33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def download_from_unpaywall(csv_path: str, out_dir: str, email: str,\n",
    "                            sleep: float = 1.0, overwrite: bool = False):\n",
    "    out_root = Path(out_dir)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    report_rows = []\n",
    "    failed_no_oa, failed_errors, successes = [], [], []\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    col_doi = find_col(df.columns, [\"DOI\"])\n",
    "    col_title = find_col(df.columns, [\"Title\"])\n",
    "    col_pmid = find_col(df.columns, [\"PMID\"])\n",
    "\n",
    "    if not col_doi:\n",
    "        raise SystemExit(\"No DOI\")\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": \"UnpaywallBulkDownloader/1.0\"})\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        doi = str(row.get(col_doi, \"\") or \"\").strip()\n",
    "        title = str(row.get(col_title, \"\") or \"\").strip()\n",
    "        pmid = str(row.get(col_pmid, \"\") or \"\").strip()\n",
    "\n",
    "        if doi.startswith(\"https://doi.org/\"):\n",
    "            doi = doi.replace(\"https://doi.org/\", \"\", 1)\n",
    "\n",
    "        if not doi:\n",
    "            report_rows.append(dict(idx=idx, doi=\"\", title=title,\n",
    "                                    status=\"skip\", url=\"\", filepath=\"\", reason=\"missing_doi\"))\n",
    "            continue\n",
    "\n",
    "        fname = safe_filename(pmid if pmid else doi.replace(\"/\", \"_\"))\n",
    "        dst = out_root / fname\n",
    "        if dst.exists() and not overwrite:\n",
    "            report_rows.append(dict(idx=idx, doi=doi, title=title,\n",
    "                                    status=\"exists\", url=\"\", filepath=str(dst.resolve()), reason=\"\"))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pdf_url, reason = get_pdf_url_from_unpaywall(doi, email, session)\n",
    "        except Exception as e:\n",
    "            failed_errors.append(doi)\n",
    "            report_rows.append(dict(idx=idx, doi=doi, title=title,\n",
    "                                    status=\"error\", url=\"\", filepath=\"\", reason=f\"unpaywall_error:{e}\"))\n",
    "            time.sleep(sleep)\n",
    "            continue\n",
    "\n",
    "        if not pdf_url:\n",
    "            failed_no_oa.append(doi)\n",
    "            report_rows.append(dict(idx=idx, doi=doi, title=title,\n",
    "                                    status=\"no_oa\", url=\"\", filepath=\"\", reason=reason))\n",
    "            time.sleep(sleep)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            stream_download(pdf_url, dst, session)\n",
    "            if dst.exists() and dst.stat().st_size > 1024:\n",
    "                successes.append(str(dst.resolve()))\n",
    "                report_rows.append(dict(idx=idx, doi=doi, title=title,\n",
    "                                        status=\"ok\", url=pdf_url, filepath=str(dst.resolve()), reason=\"\"))\n",
    "            else:\n",
    "                failed_errors.append(doi)\n",
    "                report_rows.append(dict(idx=idx, doi=doi, title=title,\n",
    "                                        status=\"error\", url=pdf_url, filepath=str(dst.resolve()), reason=\"empty_file\"))\n",
    "        except Exception as e:\n",
    "            failed_errors.append(doi)\n",
    "            report_rows.append(dict(idx=idx, doi=doi, title=title,\n",
    "                                    status=\"error\", url=pdf_url, filepath=str(dst.resolve()), reason=f\"download_error:{e}\"))\n",
    "\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    pd.DataFrame(report_rows).to_csv(out_root / \"download_report.csv\", index=False)\n",
    "    (out_root / \"failed_no_oa.txt\").write_text(\"\\n\".join(failed_no_oa), encoding=\"utf-8\")\n",
    "    (out_root / \"failed_errors.txt\").write_text(\"\\n\".join(failed_errors), encoding=\"utf-8\")\n",
    "    (out_root / \"successes.txt\").write_text(\"\\n\".join(successes), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"\"\"\n",
    "  report: {out_root / 'download_report.csv'}\n",
    "  no DOI: {out_root / 'failed_no_oa.txt'}\n",
    "  failed: {out_root / 'failed_errors.txt'}\n",
    "  successes: {out_root / 'successes.txt'}\n",
    "\"\"\")\n"
   ],
   "id": "ec03b2a20d9a1c1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "csv_path = \"literature list - pubmed.csv\"\n",
    "out_dir = \"papers\"\n",
    "email = \".edu\"\n",
    "\n",
    "download_from_unpaywall(csv_path, out_dir, email, sleep=1.0, overwrite=False)"
   ],
   "id": "16f68e1f985383af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "folder_path = \".\\papers\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".part\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "print(\"delete finsihed\")\n"
   ],
   "id": "f5de8a2348347e72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8fd0649e408522a8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
